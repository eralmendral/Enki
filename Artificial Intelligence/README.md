# Artificial Intelligence
- "It's the science and engineering of making intelligent machines." - John McCarthy, founder of ai

## Narrow/Weak AI
- AI can perform simple tasks
- Example: Apple Siri -> limited to question and answer, and basic calculations.
- The most common form of AI used today is machine learning which is a form of narrow or weak AI.
- Machine Learning uses statistical models and algorithms to draw inferences from patterns of data.
- Ex: Netflix Recommendation, Self Driving Car

## Two Types of Machine Learning
- 1. Supervised Machine Learning - infers from a set of example input-ouput pairs how to map an input to an output.
- use labeled data.
- Example: "Train an AI system to recognize an object that is round and red as an apple."

- 2. Unsupervised Machine Learning
- does not use labeled data.
- Unsupervised learning tries to find hidden structures or patterns in unlabeled data.

- Majority of AI we use today is 'narrow ai' but general ai is at the horizon.

## General/Strong AI
- AI can cope with generalized tasks much like a human
- Example: Science Fiction movies 'terminator'



## Two Types of Large Language Model (LLM)

1. Base LLM - predicts next word, based on text training data. 

2. Instruction Based LLM - fine tune on instructions and good attempts at following those instructions
   - RLHF - Reinforcement Learning with Human Feedback
   - Helpful, Honest, Harmless
  
  
## Brief History of AI
- 1940s-1950s -> AI pioneers such as Alan Turing and John McCarthy exploring the concept of "thinking machines"
-1960s-1970s -> Significant growth in AI areas such as NLP, robotics, and expert systems.
- 1980s-1990s -> AI winter, funding for AI research dries up and progress slows down.
- Early 2000s -> Advances in computing power, data storage, and machine learning algorithms spark a renewed interest in AI.
- Jan 2019 -> Microsoft invest to OpenAI
- June 2020 -> OpenAI reveals GPT-3 but only releases it to small pool of users
- May 2021 -> Google announces LaMDA(own LLM for chatbot) but doesn't release publicly.
- Nov 2022 -> OpenAI releases ChatGPT publicly
- Jan 2023 -> Microsoft invests $10 billion into OpenAI
- Feb 2023 -> Microsoft preview Bing powered by GPT-4 Google announces Bard powered by LaMDA
  


<hr/>

## Neural Networks
- Machine learning and neural networks
- Biological and artificial neural networks
- The single-layer perceptron

## What is Machine Learning
- Focuses on enabling computers to perform tasks without explicit programming
- predicing some kind of outcome
- uses data various patterns in any data set, by analyzing and outputing prediction
- Maps the Relationships - and generalizes well on unseen data.


## Deep Learning
- A subset of machine learning based on artificial neural networks



## Large Language Models (LLMs)
- A deep neural network trained on vast amount of textual data available across open internet & trained to solve Natural Language oriented use cases.
- Question & Answering
- Text Summarization
- Advanced Machine Translation
- Conversational AI & many more

## Visual Language Models (VLMs)
- Models that can learn from 2 input formats (images and text) representation using the underlying Geneartive Models.
- Ex: DALL-E 2
- Image Captioning
- Text-guided Image Generation & Manipulation
- Visual Question & Answering & many more

## Multimodal Models
- Models that acn learn from more than 2 input formats (images, text, sound & many more) represenations using the underlying Generative models.
- GPT-4 is a Multimodal Generative AI offered to ChatGPTPlus subscribers by Open AI.
- Responsible application of AI & it's societal impact is being studied.

## Foundation models
- Deep Neural Network arhitectures that computes a numerical representation of textual data.
- Foundational literally defines their application for wide range of downstream use cases due to large-scale pre-training of models.
- Largenes of a modal , measured based on the number of parameters that model hast learnt from.
